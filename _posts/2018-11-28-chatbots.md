 ---
layout: post
title: Chatbot or Human?
image: (https://i.guim.co.uk/img/media/1213b019decc7688d9ee3f14a317c5e6548d15a6/242_130_2377_1426/master/2377.jpg?width=1300&quality=85&auto=format&fit=max&s=19c8fe1a290e867631cb731855ad3558)
tags: [diary, college, artificial intelligence]
---
 
##Can you tell whether you are talking to a human or a chatbot?

In 'The charge of the chatbots: how do you tell who’s human online?', published in the Observer newspaper November 18th 2018, Tim Adams reports on advances in artificial intelligence in the field of human-computer conversation.

Some of the main points he makes are, with quotes:

1. Advances in technology are creating chatbots that mimic human behaviour to a sophisticated extent: 

> The ability of bots – a term which can describe any automated process present in a computer network – to mimic human online behaviour and language has developed sharply in the past three years.

2. One dimension of the effectiveness of these entities is the human tendency to put our trust in other human voices:

> these creations can exploit our tendency to ascribe trusted human characteristics to voices even if, on a rational level, we suspect that they are artificial. That psychology is as old as electronic communication itself.

3. The first such chatbot was developed in the USA in 1966. It was a rudimentary programme by todays standards, but it paved the way to the present. This first programme used the vocabulary input by the user in order to provide believable responses:

> In 1966, Weizenbaum, a German-American professor at the Massachusetts Institute of Technology, created a prototype chatbot that searched for keywords in conversations conducted with humans typing at keyboards. The rudimentary program would pick up these words and use them in its reply. If it did not locate a useful word, it would offer a neutral response.

4. The information that we input to the Web and Social Media is collected into data sets by corporations, and is then used by chatbot algorithms to provide more human-like discourse:

> The incalculable data sets that Google and others have harvested from our incessant online chatter are helping to make bots sound much more like us."

5. This has had, and continues to have,  social, political and economic consequences:

> at radicalisation, at how Twitter was being used to recruit Isis and at how conspiracies affected people’s decision-making when it comes to public health, when it comes to vaccines and smoking. I looked at how bots and other campaigns [that] had been used to try to manipulate the stock market.

<a href="https://www.theguardian.com/technology/2018/nov/18/how-can-you-tell-who-is-human-online-chatbots?CMP=share_btn_tw">Read the full article</a>. 
